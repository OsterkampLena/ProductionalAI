{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08304a0-43de-444c-951a-131ca00dd831",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exercise: Predicting Surface Roughness in Milling\n",
    "\n",
    "In this exercise, we use **AI-based approaches** to model a manufacturing process.  \n",
    "The goal is to predict **surface roughness `Rz`** based on:\n",
    "\n",
    "- Feed `f`\n",
    "- Cutting depth `ap`\n",
    "- Cutting width `ae`\n",
    "\n",
    "> Note: Additional factors like tool wear are ignored in this simplified example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d3fb9-410d-49d3-a4df-14a01615dd39",
   "metadata": {},
   "source": [
    "# Step 1: Loading the Dataset\n",
    "\n",
    "In this step, you will load the dataset for the milling process.  \n",
    "**Hint:** The Excel file is called `dataset_roughness.xlsx`.  \n",
    "Select only the columns: `f`, `ap`, `ae`, `Rz`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbb54b-229c-425e-a63e-4c048330b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library to handle Excel files\n",
    "import panda as pd \n",
    "\n",
    "# Load the dataset from 'dataset_roughness.xlsx'\n",
    "df = __________  # Load the excel file into a dataframe\n",
    "\n",
    "# Select relevant columns for the analysis\n",
    "columns = ['f', 'ap', 'ae', 'Rz']\n",
    "df = df[columns]\n",
    "\n",
    "# Inspect data \n",
    "print(____) # Show the first rows of the dataset\n",
    "print(f'Dataset size: {______} datapoints') # How many datapoints are in the dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106f3d2-6033-4860-be66-e5c342961491",
   "metadata": {},
   "source": [
    "# Step 2: Visualizing the Data\n",
    "\n",
    "Create a 3D scatter plot of the data.  \n",
    "Use `f` for x-axis, `ap` for y-axis, `Rz` for z-axis, and color the points by `ae`.\n",
    "\n",
    "**Hint:** Use a color map like `Blues` to visualize cutting width.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cec8f-6bc8-4f03-a16f-91262f43f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library for plotting\n",
    "import _________ as plt  # Commonly used library for plots\n",
    "\n",
    "# Visualize the dataset in 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "graph = ax.scatter(_____, _____, _____, _____, cmap='____') # Fill in: x-, y-, z-axis, colorbar and colormap\n",
    "cbar = fig.colorbar(graph, ax=ax)\n",
    "\n",
    "ax.set_xlabel('__________')  # x-axis label\n",
    "ax.set_ylabel('__________')  # y-axis label\n",
    "ax.set_zlabel('__________')  # z-axis label\n",
    "cbar.set_label('__________') # colorbar label\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d063ba-90d8-4a29-886c-7a61d6d3f777",
   "metadata": {},
   "source": [
    "# Step 3: Data Aggregation\n",
    "\n",
    "The dataset contains repeated measurements for the same parameter combinations.  \n",
    "Aggregate the data using the **mean** to have one reference value per combination.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27b647-903b-45bf-82b2-a59e73fffd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate repeated measurements using the mean\n",
    "df_agg = df.groupby(['f', 'ap', 'ae'])['Rz']._____('____').reset_index()  # Use an aggregation function to combine repeated measurements\n",
    "\n",
    "print(f'Aggregated dataset size: {_____} datapoints') # How many datapoints are in the aggregated dataset?\n",
    "\n",
    "# Visualize aggregated data in 3D (same way as in Step 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482bdb0-1fb5-4ad2-9db4-cb824717d6b3",
   "metadata": {},
   "source": [
    "# Step 4: Data Preparation for Modeling\n",
    "\n",
    "Split the dataset into **training** and **test sets**.  \n",
    "Scale the features using a standard scaling method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc87f2e-c9b7-487b-ad0f-0edd641cb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split dataset into training and test sets (70% training, 30% testing)\n",
    "data_train = ______ # Use 70% of the data for training with reproducibility(Hint: use .sample(...)) \n",
    "data_test = _______ # Remaining 30% of the data should be used for testing (Hint: use .drop(...))\n",
    "\n",
    "#Seperate input features and labels \n",
    "train_input, train_label = data_train.drop('Rz', axis=1), data_train['__________'] # Input: all columns except target column; Label = target column\n",
    "test_input, test_label = data_test.drop('Rz', axis=1), data_test['__________']     # Input: all columns except target column; Label = target column\n",
    "\n",
    "print(______) # Print the size of the train set\n",
    "print(______) # Print the size of the test set\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_input = _____  # Transform the training input\n",
    "test_input = _____   # Transform the test input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04571709-66a7-4190-82e3-ca5dda5f3484",
   "metadata": {},
   "source": [
    "# Step 5: Model Setup and Hyperparameter Optimization\n",
    "\n",
    "Set up a **MLPRegressor** and perform **GridSearchCV** to optimize hyperparameters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda31ac4-3d23-4a06-95ea-f69287b07fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import _________  # Library for cross validation\n",
    "\n",
    "# Define the neural network model\n",
    "neuralnet = _____(_______) # Hint: use ReLU activation, Adam solver, and a high number of iterations (e.g., 5000) \n",
    "\n",
    "# Set hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,10), (25,25), (50,50), (100,100)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "# Hint: Use the defined neural network, param_grid, 5-fold CV, scoring = neg_root_mean_squared_error, and parallel processing\n",
    "gridsearch_cv = GridSearchCV(\n",
    "    _______, \n",
    "    _______, \n",
    "    _______, \n",
    "    _______,  \n",
    "    _______\n",
    ")\n",
    "\n",
    "gridsearch_cv.fit(____,_____) #Fit the grid search on the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593ca12-ce61-42c2-94df-03052752c008",
   "metadata": {},
   "source": [
    "## Task 5: Evaluate the model\n",
    "\n",
    "After training, evaluate the model performance using **RMSE** on the training and test set.  \n",
    "Compare the performance of the **best model from GridSearchCV**.\n",
    "\n",
    "**Questions:**  \n",
    "1. What does RMSE indicate in a regression task?  \n",
    "2. Why might the test RMSE be higher than the training RMSE?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6d9ce-cbbf-4b33-881a-ee40571ffc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RMSE metric and numpy\n",
    "from sklearn.metrics import _________  # RMSE metric\n",
    "import numpy as np  \n",
    "\n",
    "# Use the best model from grid search\n",
    "best_model = gridsearch_cv.__________  # Attribute for the best estimator\n",
    "\n",
    "# Use the best model to predict the test set\n",
    "test_prediction = best_model.__________(__________)  # Method to generate predictions\n",
    "\n",
    "# Compute RMSE\n",
    "test_rmse = np.__________(__________(__________, __________))  # Hint: first compute the mean squared error between test labels and predictions, then take the square root\n",
    "print(f'Test set RMSE: {__________}')  # Print the computed metric\n",
    "\n",
    "# Print best grid search results\n",
    "print(f'Best grid search RMSE: {-gridsearch_cv.__________}')  # Print the attribute with the best score\n",
    "print(f'Best hyperparameters: gridsearch_cv.__________')     # Print the attribute with the best parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507966f-aee2-45c5-bda2-948bb0278245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
