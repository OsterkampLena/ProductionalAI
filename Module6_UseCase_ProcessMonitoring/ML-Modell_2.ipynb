{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8d5652",
   "metadata": {},
   "source": [
    "# Notebook 6: Neural Network Modeling of Spindle Current\n",
    "\n",
    "In the notebook 4, we modeled the **spindle current** (`ACT_CURRENT_S`) using a **Random Forest Regressor** to understand how process variables influence current consumption during milling.\n",
    "In this notebook, we will **develop a neural network model** to predict the spindle current using the same set of process features. The goal is to compare the performance of a **deep learning approach** with the previously used **Random Forest model**.\n",
    "\n",
    "By completing this exercise, you will:\n",
    "\n",
    "- Understand how to design and train a **feedforward neural network** for regression tasks  \n",
    "- Learn how to **scale data** before training a neural network  \n",
    "- Apply **performance metrics** such as **MAE**, **MSE**, and **R²** to evaluate model performance  \n",
    "- Visualize **learning curves** and compare predicted vs. actual values  \n",
    "\n",
    "### Given Information and Guidelines\n",
    "\n",
    "You are provided with:\n",
    "- Training, Validation and Testing datasets: `df_Train`, `df_Val`, and `df_Test`  \n",
    "- A list of **features** and the **target variable**\n",
    "- Evaluation metrics to use:  \n",
    "  - `Mean Absolute Error (MAE)`  \n",
    "  - `Mean Squared Error (MSE)`  \n",
    "  - `R² Score`\n",
    "\n",
    ">### The **neural network architecture and hyperparameters** (number of layers, units, dropout, learning rate, etc.) are **not provided**. You must **tune and select** them yourself through experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19721c50",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Set Up Environment\n",
    "\n",
    "Import all missing libraries in this cell, if there are more required ones depending on your neural network (e.g., tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3843494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Consistent plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "files = sorted(glob.glob(\"Rough_Train_New*.csv.gz\"))\n",
    "dfs = [pd.read_csv(f, compression=\"gzip\") for f in files]\n",
    "df_Train = pd.concat(dfs, ignore_index=True)\n",
    "df_Test = pd.read_csv(\"Rough_Test_New.csv.gz\", compression=\"gzip\")\n",
    "df_Test_2 = pd.read_csv(\"Rough_Test_D6D6D8.csv.gz\", compression=\"gzip\")\n",
    "df_Val = pd.read_csv(\"Rough_Val_New.csv.gz\", compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cffb76",
   "metadata": {},
   "source": [
    "## Step 2: Data Verification\n",
    "Before modeling, ensure that **no overlap** exists between training and test data.\n",
    "\n",
    "Look into Notebook 4 for inspiration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f7c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65a13052",
   "metadata": {},
   "source": [
    "## Step 3: Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable and feature list\n",
    "target_variables = ['ACT_CURRENT_S']\n",
    "\n",
    "features = [\n",
    "    'ACTIVE_TOOL_LENGTH', 'SPINDLE_SPEED', 'Fz_N', 'Fy_N', 'Fx_N',\n",
    "    'MultiDexel:GridX-EngagementHeight', 'MultiDexel:GridY-EngagementHeight', \n",
    "    'MultiDexel:GridZ-EngagementHeight', 'Tool_Diameter', 'Feed_Rate', \n",
    "    'Feed_per_Tooth', 'Cutting_Speed', 'ae', 'Qw', 'F_xyz'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f4906",
   "metadata": {},
   "source": [
    "## Step 4: Data Preprocessing\n",
    "\n",
    "Before training a neural network, the input features must be **standardized** to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa415d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_Train[features])\n",
    "y_train = df_Train['ACT_CURRENT_S'].values\n",
    "\n",
    "X_val = scaler.transform(df_Val[features])\n",
    "y_val = df_Val['ACT_CURRENT_S'].values\n",
    "\n",
    "X_test = scaler.transform(df_Test[features])\n",
    "y_test = df_Test['ACT_CURRENT_S'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb464f02",
   "metadata": {},
   "source": [
    "## Step 5: Build and train the neural network\n",
    "\n",
    "### Guidelines:\n",
    "- Use **Dense layers** with `ReLU` activations  \n",
    "- Include **Dropout layers** for regularization  \n",
    "- Experiment with different **numbers of layers** and **units per layer**  \n",
    "- Compile the model using:\n",
    "  - **Loss:** Mean Squared Error (`'mse'`)  \n",
    "  - **Metric:** Mean Absolute Error (`'mae'`)  \n",
    "  - **Optimizer:** `Adam` with a learning rate you choose  \n",
    "- Implement **EarlyStopping** to prevent overfitting (monitor `'val_loss'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2048dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5929bc6",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation\n",
    "\n",
    "After training, evaluate your model using the following metrics:\n",
    "- `R² Score`\n",
    "- `Mean Absolute Error (MAE)`\n",
    "- `Mean Squared Error (MSE)`\n",
    "\n",
    "Compare the results against the **Random Forest model** from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172f88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc8ff14f",
   "metadata": {},
   "source": [
    "## Step 7: Visualization\n",
    "\n",
    "Create the following visualizations to interpret model performance:\n",
    "\n",
    "1. **Learning Curves** – plot training vs. validation loss  \n",
    "   *(Hint: use `history.history['loss']` and `history.history['val_loss']`)*  \n",
    "\n",
    "2. **Predictions vs. Actual Values** – compare predicted spindle current with true values  \n",
    "   *(Hint: `plt.plot(y_test, label='Actual')` vs. `plt.plot(y_pred, label='Predicted')`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54997c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
